{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f9bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4bccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets/mics_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f961a8b9",
   "metadata": {},
   "source": [
    "# Implementation of torch Datasets based on the RIR databases\n",
    "> Pytorch Datasets that provides signals from DB_microphone classes containing RIR signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from DataScience_exploration.datasets.mics_databases import ZeaRIR, MeshRIR\n",
    "from DataScience_exploration.datasets.mics_databases import DB_microphones\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2142b0",
   "metadata": {},
   "source": [
    "## Pytorch Datasets\n",
    "> Define what information from my databases I will provide to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459cf509",
   "metadata": {},
   "source": [
    "### Dataset with a fixed environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bad2e0",
   "metadata": {},
   "source": [
    "+ The Dataset fixes the microphones that are known. For example, I set 4 microphones at specific locations to meassure the acoustics of an environment.\n",
    "+ In every iteration it returns a dictionary containing information from 1 microphone (position, signal and time samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89392701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSRirFixedEnv(Dataset):\n",
    "    \"\"\" \n",
    "    Dataset with a fixed environment\n",
    "    In this version I let the targeted microphone (to be predicted) to be any of the micros in the data\n",
    "    (including those labeled as environment)\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 mic_database: DB_microphones, \n",
    "                 ids_env: List[int],\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.db = mic_database\n",
    "        self.ids_env = ids_env        \n",
    "\n",
    "        # Environment microphones\n",
    "        self.env = {}\n",
    "        self.env['signal'] = [self.db.get_mic(i) for i in ids_env]\n",
    "        self.env['time'] = [self.db.get_time(i) for i in ids_env]\n",
    "        self.env['position'] = [self.db.get_pos(i) for i in ids_env]\n",
    "        # Change to torch tensors\n",
    "        self.env['signal'] = torch.from_numpy(np.stack(self.env['signal']).astype(np.float32))\n",
    "        self.env['time'] = torch.from_numpy(np.stack(self.env['time']).astype(np.float32))\n",
    "        self.env['position'] = torch.from_numpy(np.stack(self.env['position']).astype(np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.db.n_mics\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        In this version the environment is fixed, so in the __getitem__ \n",
    "        we only return the target \n",
    "        \"\"\"       \n",
    "        \n",
    "        return dict(signal=self.db.get_mic(idx),\n",
    "                    time=self.db.get_time(idx), \n",
    "                    position=self.db.get_pos(idx))\n",
    " \n",
    "    def get_env(self):\n",
    "        \"\"\"\n",
    "        Return the environment\n",
    "        \"\"\"\n",
    "        return self.env\n",
    "    \n",
    "    def __str__(self):\n",
    "\n",
    "        return ( \n",
    "            f\"Pytorch Dataset: {self.__class__.__name__}\\n\"\n",
    "            f\"With length: {self.__len__()} \\n\"\n",
    "            f\"Environment (mics ids): {self.ids_env}\"\n",
    "            f\"\\n\"+\n",
    "            self.db.__str__()\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8bcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched resources to download:\n",
      "- BalderRIR.mat\n",
      "Loading the resource ./data/ZeaRIR/raw/BalderRIR.mat ...\n",
      "\n",
      "Pytorch Dataset: DSRirFixedEnv\n",
      "With length: 100 \n",
      "Environment (mics ids): [10, 30, 50]\n",
      "Database: ZeaRIR\n",
      "Download: ['BalderRIR.mat']\n",
      "Load room: BalderRIR.mat\n",
      "Path to raw resource: ./data/ZeaRIR/raw/BalderRIR.mat\n",
      "Path to unpacked data folder: ./data/ZeaRIR/raw\n",
      "Sampling frequency: 11250 Hz\n",
      "Number of microphones: 100\n",
      "Number of total time samples: 3623\n",
      "Number of time samples selected: 128\n",
      "Number of sources: 1\n",
      "Signal start: 0\n",
      "Signal size: 128\n",
      "Source ID: 0\n"
     ]
    }
   ],
   "source": [
    "ds_Zea = DSRirFixedEnv(mic_database=ZeaRIR(\"./data\", dataname=\"Balder\", signal_start=0, signal_size=128),\n",
    "                      ids_env=[10, 30, 50])\n",
    "print()\n",
    "print(ds_Zea)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7340fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 100\n",
      "Position of Target (index 1). \n",
      "using list indexing:   [0.03 0.   0.  ] \n",
      "and using __getitem__: [0.03 0.   0.  ] \n",
      "\n",
      "Environment \n",
      "Positions:\n",
      "tensor([[0.3000, 0.0000, 0.0000],\n",
      "        [0.9000, 0.0000, 0.0000],\n",
      "        [1.5000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Accesing an element\n",
    "print(f\"Length of dataset: {len(ds_Zea)}\")\n",
    "print(\"Position of Target (index 1). \")\n",
    "print(f\"using list indexing:   {ds_Zea[1]['position']} \") \n",
    "print(f\"and using __getitem__: {ds_Zea.__getitem__(1)['position']} \")\n",
    "\n",
    "# Print the environment\n",
    "print()\n",
    "print(\"Environment \\nPositions:\")\n",
    "print(ds_Zea.get_env()['position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481bf9f",
   "metadata": {},
   "source": [
    "### Dataset with random environment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7974d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde306df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DS_random_pick(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mic_database: DB_microphones, \n",
    "        n_ref_mics: int = 4,  # number of mics I will pick as my environment to interpolate\n",
    "        max_combinations: int = 1000,  # number of maximum combinations\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.db = mic_database\n",
    "        self.n_ref_mics = n_ref_mics\n",
    "        self.max_combinations = max_combinations\n",
    "\n",
    "        # number of combinations without replacement of n elements in groups of r : n!/(r!*(n-r)!)\n",
    "        n = self.db.n_mics\n",
    "        r = self.n_ref_mics\n",
    "        n_comb = int(math.factorial(n) / math.factorial(n - r) / math.factorial(r))\n",
    "        self.len_comb_dataset = min(n_comb, self.max_combinations)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_comb_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ids = random.sample(range(self.db.n_mics), self.n_ref_mics + 1)\n",
    "\n",
    "        signals = [self.db.get_mic(i) for i in ids]\n",
    "        positions = [self.db.get_pos(i) for i in ids]\n",
    "        times = [self.db.get_time(i) for i in ids]\n",
    "\n",
    "        env = dict(\n",
    "             signal=torch.from_numpy(np.stack(signals[1:]).astype(np.float32)),\n",
    "             time=torch.from_numpy(np.stack(times[1:]).astype(np.float32)),\n",
    "             position=torch.from_numpy(np.stack(positions[1:]).astype(np.float32)),\n",
    "             )\n",
    "        \n",
    "        target = dict(\n",
    "             signal=torch.from_numpy(np.array(signals[0]).astype(np.float32)),\n",
    "             time=torch.from_numpy(np.array(times[0]).astype(np.float32)),\n",
    "             position=torch.from_numpy(np.array(positions[0]).astype(np.float32)),\n",
    "             )\n",
    "                   \n",
    "        return env, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c7278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched resources to download:\n",
      "- S1-M3969_npy.zip\n",
      "Unpacked folder ./data/MeshRIR/raw/S1-M3969_npy already exists. Skipping unpacking.\n",
      "\n",
      "Length of dataset: 20\n",
      "Position of Target (index 1). \n",
      "using list indexing:   tensor([0.1500, 0.3000, 0.2000]) \n",
      "and using __getitem__: tensor([0.5000, 0.1500, 0.0500]) \n",
      "\n",
      "Environment \n",
      "Positions:\n",
      "tensor([[-0.2000,  0.2500,  0.1500],\n",
      "        [ 0.4500,  0.1500,  0.0000],\n",
      "        [-0.0500, -0.4500,  0.2000],\n",
      "        [-0.1000,  0.4000, -0.1500]])\n"
     ]
    }
   ],
   "source": [
    "ds_Mesh = DS_random_pick(mic_database=MeshRIR(root=\"./data\", dataname=\"S1\", signal_start=0, signal_size=128, source_id=0),\n",
    "                         n_ref_mics=4,\n",
    "                         max_combinations=20)\n",
    "\n",
    "\n",
    "env, target = ds_Mesh[1]\n",
    "env_p, target_p = ds_Mesh.__getitem__(1)\n",
    "\n",
    "print()\n",
    "# Accesing an element\n",
    "print(f\"Length of dataset: {len(ds_Mesh)}\")\n",
    "print(\"Position of Target (index 1). \")\n",
    "print(f\"using list indexing:   {target['position']} \") \n",
    "print(f\"and using __getitem__: {target_p['position']} \")\n",
    "\n",
    "# Print the environment\n",
    "print()\n",
    "print(\"Environment \\nPositions:\")\n",
    "print(env['position'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2db3a7",
   "metadata": {},
   "source": [
    "## Pytorch lightning Datamodules\n",
    "> The pytorch lightning Datamodule organizes the torch ``Datasets`` with the operations that will have to be performed during the stages \"fit\" and \"test\". It also includes information about the ``Dataloader`` that will be used for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import torch\n",
    "import lightning.pytorch as L\n",
    "from torch.utils.data import random_split, ConcatDataset, DataLoader\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_list(x):\n",
    "    if isinstance(x, Dataset):\n",
    "        return [x]\n",
    "    elif isinstance(x, list):\n",
    "        return x\n",
    "    elif x is None:\n",
    "        return []\n",
    "    else:\n",
    "        raise TypeError(f\"Expected Dataset or list of Datasets, got {type(x)}\")\n",
    "    \n",
    "class DM_PL_DataModule(L.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 ls_datasets_train: List[torch.utils.data.Dataset] = [], \n",
    "                 ls_datasets_test: List[torch.utils.data.Dataset] = [],\n",
    "                 batch_size: int = 64, num_workers: int = 0, \n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.ls_datasets_train = ensure_list(ls_datasets_train) \n",
    "        self.ls_datasets_test = ensure_list(ls_datasets_train)\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage == \"fit\":\n",
    "            self.ds_train, self.ds_val = random_split( ConcatDataset(self.ls_datasets_train), \n",
    "                                                        [0.8, 0.2])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.ds_test = ConcatDataset(self.ls_datasets_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds_train, batch_size=self.batch_size, shuffle=True,\n",
    "            num_workers=self.num_workers, pin_memory=False, collate_fn=None)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.ds_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa5ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
