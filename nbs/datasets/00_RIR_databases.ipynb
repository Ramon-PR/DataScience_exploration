{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e965f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830bf54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets/mics_databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e83241",
   "metadata": {},
   "source": [
    "#  Class for RIR measurement databases\n",
    "> Class to get the acoustic time-series and other meta-data of RIR acoustic measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from torchvision.datasets.utils import download_url\n",
    "# For testing and adding methods to a class as patches\n",
    "from fastcore.all import patch, test_eq\n",
    "# For abstract base classes\n",
    "from abc import ABC, abstractmethod\n",
    "# For type hinting\n",
    "from typing import Optional, List, Union, Tuple, ClassVar\n",
    "from urllib.error import URLError\n",
    "from scipy.io import loadmat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc1062",
   "metadata": {},
   "source": [
    "## Helper funtions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b052fe2",
   "metadata": {},
   "source": [
    "We will define many class properties with ``@property`` and to make sure all the attributes are initialized we define the following method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71adf03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e52953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti \n",
    "#| hide \n",
    "def checked_property(attr_name: str, attr_type: type = object):\n",
    "    \"\"\" \n",
    "    Ensures that the attribute is initialized before accessing it. \n",
    "    \"\"\"\n",
    "    def getter(self):\n",
    "        value = getattr(self, attr_name)\n",
    "        if value is None:\n",
    "            raise ValueError(f\"Attribute '{attr_name}' is not initialized.\")\n",
    "        return value\n",
    "    return property(getter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64ed04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Ramon-PR/DataScience_exploration/blob/main/DataScience_exploration/datasets/mics_databases.py#L25){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### checked_property\n",
       "\n",
       ">      checked_property (attr_name:str, attr_type:type=<class 'object'>)\n",
       "\n",
       "*Ensures that the attribute is initialized before accessing it.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Ramon-PR/DataScience_exploration/blob/main/DataScience_exploration/datasets/mics_databases.py#L25){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### checked_property\n",
       "\n",
       ">      checked_property (attr_name:str, attr_type:type=<class 'object'>)\n",
       "\n",
       "*Ensures that the attribute is initialized before accessing it.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(checked_property)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a153409",
   "metadata": {},
   "source": [
    "Example of use:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a764a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mics(ABC):  \n",
    "    _fs: Optional[int] = None  \n",
    "    fs = checked_property('_fs', float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e953be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Caught ValueError: Attribute '_fs' is not initialized.\n"
     ]
    }
   ],
   "source": [
    "mic = Mics()\n",
    "print(mic._fs)  # ``_fs`` is None,\n",
    "try:\n",
    "    print(mic.fs)  # ❌ But the property ``fs`` requires _fs to be initialized to a float value\n",
    "except ValueError as e:\n",
    "    print(f\"Caught ValueError: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ba1c8",
   "metadata": {},
   "source": [
    "## Database for microphones\n",
    "> The base class to handle RIR measurements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbb74e",
   "metadata": {},
   "source": [
    "This class defines common properties and methods for the different RIR databases that will inherit from it.\n",
    "The class DB_microphones will be an abstract class (from abc import ABC, abstractmethod) \n",
    "\n",
    "+ **ABC**: base clase to declare an **A**bstract **B**ase **C**lass  \n",
    "+ **abstractmethod**: it is a decorator to indicate which methods have to be implemented by the subclasses  \n",
    "\n",
    "This is useful since this base class can not be implemented and will force the subclasses to implement certain methods `abstractmethod`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ff254",
   "metadata": {},
   "source": [
    "\n",
    "Inspired by MNIST dataset, we will download the data in a folder structure like `./root/class_name/raw`.\n",
    "\n",
    "+ **root**: is a parameter passed to the class\n",
    "+ **class_name**: is the name of the class used to download the database  \n",
    "+ **raw**: is the subfolder where the raw data is downloaded  \n",
    "\n",
    "and we will include a `mirror` list with the urls where we can find the data to download, and a list `resources` with the name of the file to download and it's md5 checksum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44de29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DB_microphones(ABC):\n",
    "    \"\"\"\n",
    "        Base class for microphone databases.\n",
    "        I define the @property methods here, so I don't have to redefine them in the subclasses.\n",
    "    \"\"\"\n",
    "\n",
    "    # ClassVar tells Pylance that these are Class variables, not instance variables.\n",
    "    # and initializes them to empty lists (although __init_subclass__ will ensure they are defined in subclasses)\n",
    "    mirrors: ClassVar[list[str]] = [] # List of urls to download the data from.\n",
    "    resources: ClassVar[list[tuple[str, str]]] = [] # List with tuples (filename, md5) for the files to download.\n",
    "\n",
    "    # This method is called when a subclass is defined. And I use it to ensure that the subclass has the required class attributes.\n",
    "    def __init_subclass__(cls, **kwargs):\n",
    "        super().__init_subclass__(**kwargs)\n",
    "        if not hasattr(cls, 'resources'):\n",
    "            raise NotImplementedError(f\"{cls.__name__} must define class attribute 'resources'\")\n",
    "        if not hasattr(cls, 'mirrors'):\n",
    "            raise NotImplementedError(f\"{cls.__name__} must define class attribute 'mirrors'\")\n",
    "\n",
    "\n",
    "    _fs: Optional[float] # Using Optional to indicate that these attributes can be None until initialized\n",
    "    _nmics: Optional[int]\n",
    "    _nt: Optional[int]\n",
    "    _n_sources: Optional[int]\n",
    "    _source_id: Optional[int]\n",
    "    _signal_size: Optional[int]\n",
    "    _signal_start: Optional[int]\n",
    "    \n",
    "    def __init__(self, \n",
    "                 root: str = \"./data\", # Path to the root directory of the database, where the data will be dowloaded \n",
    "                 dataname: str = \"RIR\", # Name of the dataset, used to create a subdirectory in the root directory\n",
    "                 signal_start: int = 0, # Start index of the signal in the data\n",
    "                 signal_size: Optional[int] = None, # int or None. Size of the signal to be extracted from the data, if None, the whole signal will be loaded.\n",
    "                 ):\n",
    "        \n",
    "        self.root = root\n",
    "        self.dataname = dataname\n",
    "        self._signal_start = signal_start\n",
    "        self._signal_size = signal_size\n",
    "\n",
    "        self._fs = None\n",
    "        self._nmics = None\n",
    "        self._nt = None\n",
    "        self._n_sources = None\n",
    "        self._source_id = None\n",
    "\n",
    "        # Create the root directory if it does not exist\n",
    "        Path(self.root).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_data(self, filepath: str):\n",
    "        \"\"\" Load the data from the given filepath.\"\"\"\n",
    "        pass\n",
    "\n",
    "    # Validated properties via helper\n",
    "    fs = checked_property(\"_fs\", float)\n",
    "    n_mics = checked_property(\"_nmics\", int)\n",
    "    nt = checked_property(\"_nt\", int)\n",
    "    n_sources = checked_property(\"_n_sources\", int)\n",
    "    source_id = checked_property(\"_source_id\", int)\n",
    "    signal_size = checked_property(\"_signal_size\", int)\n",
    "    signal_start = checked_property(\"_signal_start\", int)\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self) -> str:\n",
    "        \"\"\" Returns the path to the raw data folder. ./data/class_name/raw \"\"\"\n",
    "        return os.path.join(self.root, self.__class__.__name__, \"raw\")\n",
    "\n",
    "    @property\n",
    "    def dt(self) -> float:\n",
    "        return 1.0 / self.fs  \n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_mic(self, imic: int, start: int, size: int) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_pos(self, imic: int) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    def get_time(self, start, size):\n",
    "        return (start + np.arange(size)) * self.dt\n",
    "    \n",
    "    def _matching_resources(self,\n",
    "                         pattern: str, # pattern to look for in resource names\n",
    "                         ) -> list:\n",
    "        \"\"\" match if the pattern is found in any of the resources \"\"\" \n",
    "\n",
    "        if not hasattr(self, 'resources'):\n",
    "            print(\"No resources found.\")\n",
    "            return []\n",
    "\n",
    "        # Assuming self.resources is a list of tuples (resource_name, resource_data)\n",
    "        # where resource_name is a string and resource_data can be any type\n",
    "        matches = [(res, md5) for res, md5 in self.resources if pattern.lower() in res.lower()]\n",
    "\n",
    "        return(matches)\n",
    "\n",
    "    \n",
    "    def _download_resource(self, \n",
    "                           resource_name: str, # name of the resource to download\n",
    "                            ) -> None:\n",
    "        \n",
    "        \"\"\" download a resource by its name \"\"\"\n",
    "        \n",
    "        if not hasattr(self, 'resources'):\n",
    "            print(\"No resources found.\")\n",
    "            return\n",
    "\n",
    "        # Check the matching resources\n",
    "        down_resources = self._matching_resources(pattern = resource_name)\n",
    "        if not down_resources:\n",
    "            print(f\"No resources found matching '{resource_name}'.\")\n",
    "            return\n",
    "\n",
    "        for file, md5 in down_resources:\n",
    "            errors = []\n",
    "            for mirror in self.mirrors:\n",
    "                url = os.path.join(mirror, file)\n",
    "                try:\n",
    "                    if not os.path.isfile(os.path.join(self.raw_folder, file)):\n",
    "                        print(f\"Downloading {file} from {mirror}\")\n",
    "                        download_url(url=url, root=self.raw_folder, filename=file, md5=md5)\n",
    "\n",
    "                except URLError as e:\n",
    "                    errors.append(e)\n",
    "                    continue\n",
    "                break\n",
    "            else:\n",
    "                s = f\"Error downloading {file}:\\n\"\n",
    "                for mirror, err in zip(self.mirrors, errors):\n",
    "                    s += f\"Tried {mirror}, got:\\n{str(err)}\\n\"\n",
    "                raise RuntimeError(s)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def print_resources(cls):\n",
    "        print(f\"Resources for class {cls.__name__}:\")\n",
    "        for name, md5 in cls.resources:\n",
    "            print(f\"- {name} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1534bc",
   "metadata": {},
   "source": [
    "### Zea database\n",
    "> Database from [Elias Zea](https://www.sciencedirect.com/science/article/abs/pii/S0022460X19304316) . It will inherit from DB_micorphones "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a68c393",
   "metadata": {},
   "source": [
    "This is one of the RIR databases. It will have to implement it's own attributes:  \n",
    "    + `mirrors`  \n",
    "    + `resources`  \n",
    "    + `microphone spacing`  \n",
    "\n",
    "And the methods:  \n",
    "    + To check what resource to load  \n",
    "    + To download the resources  \n",
    "    + To unpack the downloaded resources  \n",
    "    + To load the selected resource (database/dataname)  \n",
    "    + To get the different attributes in the database: `dx`, `dt`, `fs`, `num_mics`, `num_sources`  \n",
    "    + And also the data related with the microphone recordings: `imic`, `position`, `time_samples`, `signal`  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ZeaRIR(DB_microphones):\n",
    "    \"\"\" ZeaRIR database. \"\"\"\n",
    "\n",
    "    mirrors = [\n",
    "            \"https://raw.githubusercontent.com/eliaszea/RIRIS/main/dependencies/measurementData/\"\n",
    "        ]\n",
    "\n",
    "    resources = [\n",
    "            (\"BalderRIR.mat\", \"bc904010041dc18e54a1a61b23ee3f99\"),\n",
    "            (\"FrejaRIR.mat\", \"1dedf2ab190ad48fbfa9403409418a1d\"),\n",
    "            (\"MuninRIR.mat\", \"5c90de0cbbc61128de332fffc64261c9\"),\n",
    "        ]\n",
    "    \n",
    "    _dx = 3e-2  # Distance between microphones in meters, as per the database documentation.\n",
    "\n",
    "    def __init__(self,\n",
    "                 root: str = \"./data\", # Path to the root directory of the database, where the data will be dowloaded\n",
    "                 dataname: str = \"Balder\", # String matching the name of the resources to download and load. (if several resources are available, all will be downloaded but only the first one will be loaded). \n",
    "                 signal_start: int = 0, # Start index of the signal to load.\n",
    "                 signal_size: Optional[int] = None, # Size of the signal to load. If None, the whole signal will be loaded.\n",
    "                 ):\n",
    "        super().__init__(root, dataname, signal_start, signal_size)\n",
    "\n",
    "        # Detect the matching resource\n",
    "        matched_res = self._matching_resources(dataname)\n",
    "        if not matched_res:\n",
    "            raise ValueError(f\"No resources found matching '{dataname}'.\")\n",
    "\n",
    "        print(\"Matched resources to download:\")\n",
    "        for res, _ in matched_res:\n",
    "            print(f\"- {res}\")\n",
    "\n",
    "        # Download the resource if it does not exist in the raw folder \n",
    "        self._download_resource(resource_name=dataname)\n",
    "\n",
    "        # Extract data if compressed\n",
    "        self._unpack_resource()\n",
    "\n",
    "        # Load the data from the first matching resource\n",
    "        self.dataname = matched_res[0][0]\n",
    "        self.load_data(os.path.join(self.raw_folder, self.dataname))\n",
    "\n",
    "\n",
    "    def load_data(self, filepath: str):\n",
    "        \"\"\" Loads all the Matlab data from the given filepath.\"\"\"\n",
    "        print(f\"Loading the resource {filepath} ...\")\n",
    "        _rawdata = loadmat(filepath, simplify_cells=True)\n",
    "        self._fs = _rawdata['out']['fs']\n",
    "\n",
    "        T = _rawdata['out']['T']\n",
    "        M = _rawdata['out']['M']\n",
    "\n",
    "        assert self._signal_start is not None\n",
    "        start_sample = self._signal_start\n",
    "        if self._signal_size is None:\n",
    "            self._signal_size = T - start_sample\n",
    "\n",
    "        assert self._signal_size is not None\n",
    "        last_sample = self._signal_start + self._signal_size\n",
    "\n",
    "        assert (start_sample >= 0 and start_sample < T), f\"The start_signal should be in [0, {T-1}].\"\n",
    "        assert (last_sample > 0 and last_sample <= T), f\"The size_signal should be in [1, {T-start_sample}].\"\n",
    "        \n",
    "        self._RIR = _rawdata['out']['image'][start_sample:last_sample, :]  # Transpose to have (n_mics, n_sources, nt)\n",
    "\n",
    "        self._nmics = M\n",
    "        self._nt = self.signal_size\n",
    "        self._n_sources = 1\n",
    "        self._source_id = 0\n",
    "\n",
    "\n",
    "    def get_mic(self, imic: int, start: int, size: int) -> np.ndarray:\n",
    "        return self._RIR[start:start + size, imic]\n",
    "    \n",
    "\n",
    "    def get_pos(self, imic: int) -> np.ndarray:\n",
    "        assert 0 <= imic < self.n_mics, f\"Microphone index {imic} out of range [0, {self.n_mics - 1}]\"\n",
    "        return imic * self._dx * np.array([1])\n",
    "\n",
    "    def _unpack_resource(self):\n",
    "        \"\"\" Unpack the resource if it is compressed. \"\"\"\n",
    "        # For now, I assume the resources are not compressed, but this can be extended later.\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33ba658",
   "metadata": {},
   "source": [
    "#### Checks that Zea database works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched resources to download:\n",
      "- BalderRIR.mat\n",
      "- FrejaRIR.mat\n",
      "- MuninRIR.mat\n",
      "Loading the resource ./data/ZeaRIR/raw/BalderRIR.mat ...\n"
     ]
    }
   ],
   "source": [
    "db = ZeaRIR(root=\"./data\", dataname=\"RIR\", signal_start=0, signal_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4c42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: ZeaRIR\n",
      "Room: BalderRIR.mat\n",
      "Sampling frequency: 11250 Hz\n",
      "Number of microphones: 100\n",
      "Number of time samples selected: 128\n",
      "Number of sources: 1\n",
      "Signal start: 0\n",
      "Signal size: 128\n",
      "Source ID: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Database: {db.__class__.__name__}\")\n",
    "print(f\"Room: {db.dataname}\")\n",
    "print(f\"Sampling frequency: {db.fs} Hz\")\n",
    "print(f\"Number of microphones: {db.n_mics}\")\n",
    "print(f\"Number of time samples selected: {db.nt}\")\n",
    "print(f\"Number of sources: {db.n_sources}\")\n",
    "print(f\"Signal start: {db.signal_start}\")\n",
    "print(f\"Signal size: {db.signal_size}\")\n",
    "print(f\"Source ID: {db.source_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789f4b1",
   "metadata": {},
   "source": [
    "Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7211e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "0\n",
      "11250\n",
      "(128, 100)\n",
      "[ 0.00041836  0.0001148  -0.00129174  0.00162724]\n",
      "[0.03]\n",
      "[0.00000000e+00 8.88888889e-05 1.77777778e-04 2.66666667e-04]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(db._signal_size)\n",
    "print(db._signal_start)\n",
    "print(db._fs)\n",
    "print(db._RIR.shape)\n",
    "print(db.get_mic(imic=0, start=0, size=4))  # Get the first 4 samples of the first microphone\n",
    "print(db.get_pos(imic=1))  # Get the position of the second microphone\n",
    "print(db.get_time(start=0, size=4))  # Get the time for the first 4 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5de5721",
   "metadata": {},
   "source": [
    "This is how I have calculated the MD5 of each file in resources to add it in the class definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f82a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.utils import calculate_md5, check_md5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0956f60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched resources to download:\n",
      "- BalderRIR.mat\n",
      "Loading the resource ./data/ZeaRIR/raw/BalderRIR.mat ...\n",
      "File: BalderRIR.mat, MD5: bc904010041dc18e54a1a61b23ee3f99\n",
      "File: FrejaRIR.mat, MD5: 1dedf2ab190ad48fbfa9403409418a1d\n",
      "File: MuninRIR.mat, MD5: 5c90de0cbbc61128de332fffc64261c9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db = ZeaRIR(root=\"./data\")\n",
    "for file, md5_class in db.resources:\n",
    "    url = os.path.join(db.mirrors[0], file)\n",
    "    download_url(url, root=db.raw_folder, filename=file)\n",
    "    md5 = calculate_md5(os.path.join(db.raw_folder, file))\n",
    "    print(f\"File: {file}, MD5: {md5}\")\n",
    "    assert check_md5(os.path.join(db.raw_folder, file), md5_class), (\n",
    "    f\"Check the MD5 of the resource '{file}' for the class '{db.__class__.__name__}' \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08caa8",
   "metadata": {},
   "source": [
    "Here we implement the option to print the resources that can be downloaded.  \n",
    "I use `@patch` from `fastcore` to add this function to the class after the class has already been defined.  \n",
    "Since we just want to print the resources (class attributes), it is a class method, so it does not need an instance of the class.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848854c5",
   "metadata": {},
   "source": [
    "\n",
    "::: {.callout-note}\n",
    "Pylance linting does not like `patch` and will underline it as a possible error.  \n",
    "I have added it directly to the class (the following code is just for testing purposes).\n",
    "([This is a callout from Quarto](https://quarto.org/docs/authoring/callouts.html#callout-types))\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d47ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch(cls_method=True)  \n",
    "def print_resources(cls: DB_microphones):\n",
    "    print(f\"Resources for class {cls.__name__}:\")\n",
    "    for name, md5 in cls.resources:\n",
    "        print(f\"- {name} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe16a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZeaRIR.print_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f215f48c",
   "metadata": {},
   "source": [
    "Now let's implement a method to recognize if a string pattern provided as dataname matches any resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17139a",
   "metadata": {},
   "source": [
    "> Downloading:  \n",
    "\n",
    "We give the option to give a string pattern to download several resources,  \n",
    "but each instance of the class should be used to provide measurements of only one of the resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, _ =  db._matching_resources(\"balder\")[0]\n",
    "# print(res)\n",
    "pathfname = os.path.join(db.raw_folder, res)\n",
    "print(f\"Path to resource: {pathfname}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84083a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db = ZeaRIR(root=\"./data\", dataname=\"RIR\")\n",
    "db._matching_resources(\"RIR\")\n",
    "db._download_resource(\"RIR\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3926ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f271b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdd03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f16bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
